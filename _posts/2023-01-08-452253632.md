---
title: "pruning for sparsity – turns out [some LLMs work just as ..."
tags: articles-23041592
canonical: https://feeds.feedblitz.com/~/723730378/0/marginalrevolution~Nathan-Labenz-on-AI-pricing.html
hide_title: true
---

pruning for sparsity – turns out [some LLMs work just as well if you set 60% of the weights to zero](https://feeds.feedblitz.com/~/t/0/0/marginalrevolution/~https://secure-web.cisco.com/1LC_3KEJMsW1fzj626qxXR7y_MeRzdNmWKGDPriV9lmVzRK3WTgQ04W85j2rRud2nHpbGxFYfvSzjQB9B-gLPMSJyIiaG0CcUNzwNOv25HcFx9LXOONxwrn7rGGW6WhBAspIzkzSHlhVOawfo2GectTKs2enuxnvNtNKJa-6tEsVg05r6swcHtBV1F_igMj-eQmfib2hfhqV1Us7Kbm_1b41MVe-zzE_q6BiwJVA1hhAZdkX5SvTl5y1hVThwnmSmqvwdULuEgWUDuuLZt66jadKMLGlLECOXF5swruTnOyBoIVatSK_ja9AdY328idGoEL7_gM-TETwjWfkwv1AnbztrFD5LFoErxkISsNx5eI0ZW6Ay1--_EJkGBiB6g41Z709HvImk8AaGkn39gMOhD4lxfELuSizJuJ0dVbHDbIZut2T0o4_Kd_UVHMXsxSYA/https%3A%2F%2Ftwitter.com%2FAlphaSignalAI%2Fstatus%2F1610789373221474304) (though this likely isn’t true if you’re using Chinchilla-optimal training)


[[<cite>_[Nathan Labenz on AI pricing](https://feeds.feedblitz.com/~/723730378/0/marginalrevolution~Nathan-Labenz-on-AI-pricing.html){:target="_blank"}_</cite> by Tyler Cowen ![favicon](https://s2.googleusercontent.com/s2/favicons?domain=feeds.feedblitz.com){:class="source-favicon"}<br>
_More_: [Readwise URL](https://readwise.io/open/452253632){:target="_blank"}
::wrap]]